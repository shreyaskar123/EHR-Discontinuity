{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "477b71d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/PHShome/se197/anaconda3/lib/python3.8/site-packages/pandas/core/series.py:4509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/PHShome/se197/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:26:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/PHShome/se197/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:29:10] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/PHShome/se197/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:31:57] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/PHShome/se197/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:34:44] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/PHShome/se197/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:37:32] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/PHShome/se197/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:40:19] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.8764469832354079\n",
      "0.5326440751413136\n",
      "0.5288868321223053\n",
      "0.7613469302410854\n",
      "0.3243241619072422\n",
      "Test gpop\n",
      "0.8612883925009972\n",
      "0.09792477302204929\n",
      "0.5141545943288508\n",
      "0.7060075693546318\n",
      "0.366424537506625\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/PHShome/se197/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:43:04] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Train high\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/PHShome/se197/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:45:49] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/PHShome/se197/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:48:33] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/PHShome/se197/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:51:15] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/PHShome/se197/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:53:59] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/PHShome/se197/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:56:44] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.9063468613936724\n",
      "0.5160918338844303\n",
      "0.5156792335007184\n",
      "0.760208089754885\n",
      "0.2723743559342057\n",
      "\n",
      "Test high\n",
      "0.9029024848611401\n",
      "0.04123711340206186\n",
      "0.5013903645653492\n",
      "0.6877348069272347\n",
      "0.2969425348867385\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/PHShome/se197/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:27] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Train high\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/PHShome/se197/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:02:09] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/PHShome/se197/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:04:54] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/PHShome/se197/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:07:37] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/PHShome/se197/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:10:20] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/PHShome/se197/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:13:02] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.8435658044910254\n",
      "0.5366115310174904\n",
      "0.533717916211222\n",
      "0.7394284315073365\n",
      "0.38499102060810547\n",
      "\n",
      "Test high\n",
      "0.8280206146211109\n",
      "0.15399061032863848\n",
      "0.5287340100886644\n",
      "0.6863436466933653\n",
      "0.4322244893583677\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "medicare = pd.read_csv(\"/netapp2/home/se197/data/CMS/Data/medicare.csv\")\n",
    "\n",
    "\n",
    "train_set = medicare[medicare.Hospital != 'BWH'] # MGH; n = 204014\n",
    "validation_set = medicare[medicare.Hospital == 'BWH'] # BWH and Neither; n = 115726\n",
    "import numpy as np\n",
    "\n",
    "fifty_perc_EHR_cont = np.percentile(medicare['Cal_MPEC_R0'],50)\n",
    "train_set_high = train_set[train_set.Cal_MPEC_R0 >= fifty_perc_EHR_cont]\n",
    "train_set_low= train_set[train_set.Cal_MPEC_R0 < fifty_perc_EHR_cont]\n",
    "\n",
    "validation_set_high = validation_set[validation_set.Cal_MPEC_R0 >= fifty_perc_EHR_cont]\n",
    "validation_set_low = validation_set[validation_set.Cal_MPEC_R0 < fifty_perc_EHR_cont]\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "predictor_variable = [\n",
    "        'Co_CAD_R0', 'Co_Embolism_R0', 'Co_DVT_R0', 'Co_PE_R0', 'Co_AFib_R0',\n",
    "        'Co_Hypertension_R0', 'Co_Hyperlipidemia_R0', 'Co_Atherosclerosis_R0',\n",
    "        'Co_HF_R0', 'Co_HemoStroke_R0', 'Co_IscheStroke_R0', 'Co_OthStroke_R0',\n",
    "        'Co_TIA_R0', 'Co_COPD_R0', 'Co_Asthma_R0', 'Co_Pneumonia_R0', 'Co_Alcoholabuse_R0',\n",
    "        'Co_Drugabuse_R0', 'Co_Epilepsy_R0', 'Co_Cancer_R0', 'Co_MorbidObesity_R0',\n",
    "        'Co_Dementia_R0', 'Co_Depression_R0', 'Co_Bipolar_R0', 'Co_Psychosis_R0',\n",
    "        'Co_Personalitydisorder_R0', 'Co_Adjustmentdisorder_R0', 'Co_Anxiety_R0',\n",
    "        'Co_Generalizedanxiety_R0', 'Co_OldMI_R0', 'Co_AcuteMI_R0', 'Co_PUD_R0',\n",
    "        'Co_UpperGIbleed_R0', 'Co_LowerGIbleed_R0', 'Co_Urogenitalbleed_R0',\n",
    "        'Co_Othbleed_R0', 'Co_PVD_R0', 'Co_LiverDisease_R0', 'Co_MRI_R0',\n",
    "        'Co_ESRD_R0', 'Co_Obesity_R0', 'Co_Sepsis_R0', 'Co_Osteoarthritis_R0',\n",
    "        'Co_RA_R0', 'Co_NeuroPain_R0', 'Co_NeckPain_R0', 'Co_OthArthritis_R0',\n",
    "        'Co_Osteoporosis_R0', 'Co_Fibromyalgia_R0', 'Co_Migraine_R0', 'Co_Headache_R0',\n",
    "        'Co_OthPain_R0', 'Co_GeneralizedPain_R0', 'Co_PainDisorder_R0',\n",
    "        'Co_Falls_R0', 'Co_CoagulationDisorder_R0', 'Co_WhiteBloodCell_R0', 'Co_Parkinson_R0',\n",
    "        'Co_Anemia_R0', 'Co_UrinaryIncontinence_R0', 'Co_DecubitusUlcer_R0',\n",
    "        'Co_Oxygen_R0', 'Co_Mammography_R0', 'Co_PapTest_R0', 'Co_PSATest_R0',\n",
    "        'Co_Colonoscopy_R0', 'Co_FecalOccultTest_R0', 'Co_FluShot_R0', 'Co_PneumococcalVaccine_R0', 'Co_RenalDysfunction_R0', 'Co_Valvular_R0', 'Co_Hosp_Prior30Days_R0',\n",
    "        'Co_RX_Antibiotic_R0', 'Co_RX_Corticosteroid_R0', 'Co_RX_Aspirin_R0', 'Co_RX_Dipyridamole_R0',\n",
    "        'Co_RX_Clopidogrel_R0', 'Co_RX_Prasugrel_R0', 'Co_RX_Cilostazol_R0', 'Co_RX_Ticlopidine_R0',\n",
    "        'Co_RX_Ticagrelor_R0', 'Co_RX_OthAntiplatelet_R0', 'Co_RX_NSAIDs_R0',\n",
    "        'Co_RX_Opioid_R0', 'Co_RX_Antidepressant_R0', 'Co_RX_AAntipsychotic_R0', 'Co_RX_TAntipsychotic_R0',\n",
    "        'Co_RX_Anticonvulsant_R0', 'Co_RX_PPI_R0', 'Co_RX_H2Receptor_R0', 'Co_RX_OthGastro_R0',\n",
    "        'Co_RX_ACE_R0', 'Co_RX_ARB_R0', 'Co_RX_BBlocker_R0', 'Co_RX_CCB_R0', 'Co_RX_Thiazide_R0',\n",
    "        'Co_RX_Loop_R0', 'Co_RX_Potassium_R0', 'Co_RX_Nitrates_R0', 'Co_RX_Aliskiren_R0',\n",
    "        'Co_RX_OthAntihypertensive_R0', 'Co_RX_Antiarrhythmic_R0', 'Co_RX_OthAnticoagulant_R0',\n",
    "        'Co_RX_Insulin_R0', 'Co_RX_Noninsulin_R0', 'Co_RX_Digoxin_R0', 'Co_RX_Statin_R0',\n",
    "        'Co_RX_Lipid_R0', 'Co_RX_Lithium_R0', 'Co_RX_Benzo_R0', 'Co_RX_ZDrugs_R0',\n",
    "        'Co_RX_OthAnxiolytic_R0', 'Co_RX_Dementia_R0', 'Co_RX_Hormone_R0',\n",
    "        'Co_RX_Osteoporosis_R0', 'Co_N_Drugs_R0', 'Co_N_Hosp_R0', 'Co_Total_HospLOS_R0',\n",
    "        'Co_N_MDVisit_R0', 'Co_RX_AnyAspirin_R0', 'Co_RX_AspirinMono_R0', 'Co_RX_ClopidogrelMono_R0',\n",
    "        'Co_RX_AspirinClopidogrel_R0', 'Co_RX_DM_R0', 'Co_RX_Antipsychotic_R0'\n",
    "]\n",
    "\n",
    "co_train_gpop = train_set[predictor_variable]\n",
    "co_train_high = train_set_high[predictor_variable]\n",
    "co_train_low = train_set_low[predictor_variable]\n",
    "\n",
    "co_validation_gpop = validation_set[predictor_variable]\n",
    "co_validation_high = validation_set_high[predictor_variable]\n",
    "co_validation_low = validation_set_low[predictor_variable]\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "out_train_cardio_gpop = train_set['Out_comp_cardiovascular_RC1']\n",
    "out_train_cardio_high = train_set_high['Out_comp_cardiovascular_RC1']\n",
    "out_train_cardio_low = train_set_low['Out_comp_cardiovascular_RC1']\n",
    "\n",
    "out_validation_cardio_gpop = validation_set['Out_comp_cardiovascular_RC1']\n",
    "out_validation_cardio_high = validation_set_high['Out_comp_cardiovascular_RC1']\n",
    "out_validation_cardio_low = validation_set_low['Out_comp_cardiovascular_RC1']\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "'''\n",
    "NOT USING THIS\n",
    "INSTEAD USING XGBOOST: A FASTER IMPLEMENTATION OF XGBOOST \n",
    "https://github.com/dmlc/xgboost/tree/master/python-package\n",
    "def GBT(X,y): \n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "\n",
    "    param_grid = [{\n",
    "        'learning_rate': [0.05,0.1,0.2],\n",
    "        'n_estimators': [100,150,200]\n",
    "    }]\n",
    "    \n",
    "    boost_clf = GradientBoostingRegressor()\n",
    "    boosting_grid_search = GridSearchCV(estimator = boost_clf, param_grid = param_grid)\n",
    "    best_clf = boosting_grid_search.fit(X, y)\n",
    "    return best_clf\n",
    "'''\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "def xgBoost(X,y):\n",
    "    from xgboost import XGBClassifier\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    model = XGBClassifier()\n",
    "    param_grid = [{\n",
    "        'max_depth': [2,3],\n",
    "        'n_estimators': [60,160],\n",
    "    }]\n",
    "    grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    n_jobs = 10,\n",
    "    cv = 5,\n",
    "    verbose=True\n",
    ")\n",
    "    best_clf = grid_search.fit(X,y)\n",
    "    return best_clf\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "def scores(X,y):\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import f1_score\n",
    "    from sklearn.metrics import fbeta_score\n",
    "    from sklearn.metrics import roc_auc_score \n",
    "    from sklearn.metrics import log_loss\n",
    "\n",
    "    pred = best_clf.predict(X)\n",
    "    actual = y\n",
    "    print(accuracy_score(actual,pred))\n",
    "    print(f1_score(actual,pred))\n",
    "    print(fbeta_score(actual,pred, average = 'macro', beta = 2))\n",
    "    print(roc_auc_score(actual, best_clf.predict_proba(X)[:,1]))\n",
    "    print(log_loss(actual,best_clf.predict_proba(X)[:,1]))\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "def cross_val(X,y):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.model_selection import cross_validate\n",
    "    from sklearn.metrics import log_loss\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from sklearn.metrics import fbeta_score\n",
    "    import sklearn\n",
    "    import numpy as np\n",
    "    cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    log_loss = [] \n",
    "    auc = [] \n",
    "    accuracy = []\n",
    "    f1 = []\n",
    "    f2 = [] \n",
    "    for train_index, test_index in cv.split(X):\n",
    "        X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "        model = xgBoost(X_train, y_train)\n",
    "        prob = model.predict_proba(X_test)[:,1] # prob is a vector of probabilities \n",
    "        pred = np.round(model.predict_proba(X_test)[:,1]) # pred is the rounded predictions \n",
    "        log_loss.append(sklearn.metrics.log_loss(y_test, prob))\n",
    "        auc.append(sklearn.metrics.roc_auc_score(y_test, prob))\n",
    "        accuracy.append(sklearn.metrics.accuracy_score(y_test, pred))\n",
    "        f1.append(sklearn.metrics.f1_score(y_test, pred, average = 'macro'))\n",
    "        f2.append(fbeta_score(y_test,pred, average = 'macro', beta = 2))\n",
    "    print(np.mean(accuracy))\n",
    "    print(np.mean(f1))\n",
    "    print(np.mean(f2))\n",
    "    print(np.mean(auc))\n",
    "    print(np.mean(log_loss))\n",
    "\n",
    "\n",
    "# # FAMD Transformation\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "from prince import FAMD\n",
    "famd = FAMD(n_components = 15, n_iter = 3, random_state = 101)\n",
    "\n",
    "for (colName, colData) in co_train_gpop.iteritems():\n",
    "    if (colName != 'Co_N_Drugs_R0' and colName!= 'Co_N_Hosp_R0' and colName != 'Co_Total_HospLOS_R0' and colName != 'Co_N_MDVisit_R0'):\n",
    "        co_train_gpop[colName].replace((1,0) ,('yes','no'), inplace = True)\n",
    "        co_train_low[colName].replace((1,0) ,('yes','no'), inplace = True)\n",
    "        co_train_high[colName].replace((1,0) ,('yes','no'), inplace = True)\n",
    "        co_validation_gpop[colName].replace((1,0), ('yes','no'), inplace = True)\n",
    "        co_validation_high[colName].replace((1,0), ('yes','no'), inplace = True)\n",
    "        co_validation_low[colName].replace((1,0), ('yes','no'), inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "famd.fit(co_train_gpop)\n",
    "co_train_gpop_FAMD = famd.transform(co_train_gpop)  \n",
    "\n",
    "famd.fit(co_train_high)\n",
    "co_train_high_FAMD = famd.transform(co_train_high)  \n",
    "\n",
    "famd.fit(co_train_low)\n",
    "co_train_low_FAMD = famd.transform(co_train_low)  \n",
    "\n",
    "famd.fit(co_validation_gpop)\n",
    "co_validation_gpop_FAMD = famd.transform(co_validation_gpop)    \n",
    "\n",
    "famd.fit(co_validation_high)\n",
    "co_validation_high_FAMD = famd.transform(co_validation_high)    \n",
    "\n",
    "famd.fit(co_validation_low)\n",
    "co_validation_low_FAMD = famd.transform(co_validation_low)    \n",
    "\n",
    "\n",
    "# # General Population\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "best_clf = xgBoost(co_train_gpop_FAMD, out_train_cardio_gpop)\n",
    "\n",
    "print(\"Train gpop\", file = open('comp_famd_gbt_ehr.out', 'a'))\n",
    "\n",
    "cross_val(co_train_gpop_FAMD, out_train_cardio_gpop)\n",
    "\n",
    "print(\"Test gpop\")\n",
    "\n",
    "scores(co_validation_gpop_FAMD, out_validation_cardio_gpop)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # High Continuity \n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "best_clf = xgBoost(co_train_high_FAMD, out_train_cardio_high)\n",
    "\n",
    "print(\"Train high\")\n",
    "\n",
    "cross_val(co_train_high_FAMD, out_train_cardio_high)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Test high\")\n",
    "\n",
    "scores(co_validation_high_FAMD, out_validation_cardio_high)\n",
    "\n",
    "\n",
    "# # Low Continuity\n",
    "# \n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "best_clf = xgBoost(co_train_low_FAMD, out_train_cardio_low)\n",
    "\n",
    "print(\"Train high\")\n",
    "\n",
    "cross_val(co_train_low_FAMD, out_train_cardio_low)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Test high\")\n",
    "\n",
    "scores(co_validation_low_FAMD, out_validation_cardio_low)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a2815a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
